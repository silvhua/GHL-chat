{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(r\"/home/silvhua/custom_python\")\n",
    "sys.path.append(r'/home/silvhua/repositories/GHL-chat/src/')\n",
    "from silvhua import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to wrap text within cells\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/silvhua/repositories/notion/data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat history length: 2\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `placeholder_function` with `Tell me more about the program`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mNone\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "  {\"response\": \"I'm Amanda - creator of the Strong and Sassy programme. I am a degree qualified nutritionist and coach with over 10 years experience. I educate women about the importance of health and wellness, so they can live a sustainable, healthy and balanced lifestyle. The Strong and Sassy programme includes 1:1 nutrition habit coaching, personalized resistance training programs, weekly group coaching calls, in-house mindset coaching, nutrition education, unlimited accountability, community meet-ups, and free recipe e-books.\", \"alert_human\": false}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response time: 7.767297029495239 seconds\n",
      "Reply from `chat_with_chatbot`: \n",
      "  {\"response\": \"I'm Amanda - creator of the Strong and Sassy programme. I am a degree qualified nutritionist and coach with over 10 years experience. I educate women about the importance of health and wellness, so they can live a sustainable, healthy and balanced lifestyle. The Strong and Sassy programme includes 1:1 nutrition habit coaching, personalized resistance training programs, weekly group coaching calls, in-house mindset coaching, nutrition education, unlimited accountability, community meet-ups, and free recipe e-books.\", \"alert_human\": false}\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Chatbot_Response(BaseModel):\n",
    "    response: str = Field(description=\"The response to the InboundMessage.\")\n",
    "    alert_human: bool = Field(description=\"Whether or not to alert a human to review the response.\")\n",
    "\n",
    "def create_system_message(\n",
    "        business_name, prompts_filepath='../prompts',\n",
    "        examples_filepath='../data/chat_examples', doc_filepath='../data/rag_docs'\n",
    "        ):\n",
    "    \n",
    "    instructions = load_txt(f'{business_name}.md', prompts_filepath)\n",
    "    examples = load_txt(f'{business_name}.txt', examples_filepath)\n",
    "    document = load_txt(f'{business_name}_doc.md', doc_filepath)\n",
    "\n",
    "    system_message = f\"\"\"# Stage 1\n",
    "\n",
    "{instructions}\n",
    "\n",
    "Return your response on a JSON format with the following keys:\n",
    "- \"response\" (string): The response to the InboundMessage.\n",
    "- \"alert_human\" (True or False): Whether or not to alert a human to review the response.\n",
    "\n",
    "## Examples\n",
    "\n",
    "Below are example conversations with leads. Each lead as a unique contact ID.\n",
    "An InboundMessage is from the lead. An OutboundMessage is from you.\n",
    "\n",
    "{examples}\n",
    "\n",
    "## Relevant documentation\n",
    "\n",
    "{document}\n",
    "\n",
    "# Stage 2\n",
    "\n",
    "Review your response from stage 1. \n",
    "Revise your response if needed to make sure you followed the instructions.\n",
    "Make sure that if the question cannot be answered through the documentation, \n",
    "you return \"[ALERT HUMAN]\".\n",
    "\n",
    "# Stage 3\n",
    "\n",
    "Review your response from stage 2 to ensure your response is concise.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    Write the next OutboundMessage based on the following InboundMessage, \n",
    "    which is delimited by triple backticks: ```{InboundMessage}```\n",
    "    \"\"\"\n",
    "    system_message = f'{system_message}{prompt}'\n",
    "    return system_message\n",
    "\n",
    "def create_chatbot(contactId, system_message, tools, model=\"gpt-3.5-turbo-1106\", verbose=True):\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        temperature = 0,\n",
    "        openai_organization=os.environ['openai_organization'],\n",
    "        openai_api_key=os.environ['openai_api_key'],\n",
    "        model=model, \n",
    "        model_kwargs={\"response_format\": {\"type\": \"json_object\"}} # https://platform.openai.com/docs/guides/text-generation/json-mode  # https://api.python.langchain.com/en/latest/chat_models/langchain_community.chat_models.openai.ChatOpenAI.html?highlight=chatopenai#\n",
    "        )\n",
    "    message_history = DynamoDBChatMessageHistory(\n",
    "        table_name=\"SessionTable\", session_id=contactId,\n",
    "        key={\n",
    "            \"SessionId\": contactId,\n",
    "            \"type\": 'ChatHistory',\n",
    "            }\n",
    "        )\n",
    "    system_message = SystemMessage(\n",
    "        content=(system_message),\n",
    "        input_variables=['InboundMessage']\n",
    "    )\n",
    "\n",
    "    prompt = OpenAIFunctionsAgent.create_prompt(\n",
    "        system_message=system_message,\n",
    "        extra_prompt_messages=[\n",
    "            MessagesPlaceholder(variable_name='chat_history')\n",
    "            ]\n",
    "    )\n",
    "\n",
    "    parser = SimpleJsonOutputParser(pydantic_object=Chatbot_Response)\n",
    "    agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt)\n",
    "    agent_executor = AgentExecutor( # Example of creating a custom agent: https://python.langchain.com/docs/modules/agents/how_to/custom_agent\n",
    "        agent=agent, tools=tools, \n",
    "        verbose=verbose, return_intermediate_steps=True,\n",
    "        parser=parser  # Add the parser instance to the agent_executor\n",
    "        )\n",
    "    agent_info = {\n",
    "        'agent': agent,\n",
    "        'agent_executor': agent_executor,\n",
    "        'chat_history': message_history.messages\n",
    "    }\n",
    "    return agent_info\n",
    "\n",
    "def chat_with_chatbot(user_input, agent_info):\n",
    "    start_time = time()\n",
    "    print(f'Chat history length: {len(agent_info[\"chat_history\"])}')\n",
    "    chat_history = agent_info['chat_history']\n",
    "    result = agent_info['agent_executor']({\n",
    "            \"input\": user_input,\n",
    "            \"chat_history\": chat_history\n",
    "        })  \n",
    "    print(f'Response time: {time() - start_time} seconds')\n",
    "    \n",
    "    return result\n",
    "\n",
    "def alert_human(str) -> str:\n",
    "    return {\"response\": \"[ALERT HUMAN]\", \"alert_human\": True}\n",
    "\n",
    "def placeholder_function(str):\n",
    "    return None\n",
    "\n",
    "tools = [\n",
    "    # Tool(\n",
    "    #     name=f\"alert_human_function\",\n",
    "    #     func=alert_human,\n",
    "    #     description=f\"If the InboundMessage cannot be answered from your instructions or documentation, use this function.\",\n",
    "    # ),\n",
    "    Tool(\n",
    "        name=f\"placeholder_function\",\n",
    "        func=placeholder_function,\n",
    "        description=f\"This function does not do anything.\",\n",
    "    )\n",
    "]\n",
    "\n",
    "conversation_id = 9.1\n",
    "InboundMessage = \"Tell me more about the program\"\n",
    "reply_dict[conversation_id] = dict()\n",
    "question_id = 1\n",
    "\n",
    "contactId = contacts['me_mcloone']\n",
    "system_message_dict[conversation_id] = create_system_message(\n",
    "    'CoachMcloone', prompts_filepath='../prompts',\n",
    "    examples_filepath='../data/chat_examples', doc_filepath='../data/rag_docs'\n",
    ")\n",
    "conversation_dict[conversation_id] = create_chatbot(\n",
    "    contactId, system_message_dict[conversation_id], tools=tools,\n",
    "    # model='gpt-4-32k'\n",
    "    )\n",
    "\n",
    "reply_dict[conversation_id][question_id] = chat_with_chatbot(\n",
    "    InboundMessage, conversation_dict[conversation_id]\n",
    ")\n",
    "reply_text = reply_dict[conversation_id][question_id][\"output\"]\n",
    "print(f'Reply from `chat_with_chatbot`: {reply_text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ghl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
